{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms#, utils\n",
    "# import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "from data_loader import RescaleT\n",
    "from data_loader import ToTensor\n",
    "from data_loader import ToTensorLab\n",
    "from data_loader import SalObjDataset\n",
    "\n",
    "from model import U2NET # full size version 173.6 MB\n",
    "from model import U2NETP # small version u2net 4.7 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the predicted SOD probability map\n",
    "def normPRED(d):\n",
    "    ma = torch.max(d)\n",
    "    mi = torch.min(d)\n",
    "\n",
    "    dn = (d-mi)/(ma-mi)\n",
    "\n",
    "    return dn\n",
    "\n",
    "def mask_output(image_name,pred,d_dir):\n",
    "\n",
    "    predict = pred\n",
    "    predict = predict.squeeze()\n",
    "    predict_np = predict.cpu().data.numpy()\n",
    "\n",
    "    im = Image.fromarray(predict_np*255).convert('RGB')\n",
    "    img_name = image_name.split(os.sep)[-1]\n",
    "    image = io.imread(image_name)\n",
    "    imo = im.resize((image.shape[1],image.shape[0]),resample=Image.BILINEAR)\n",
    "\n",
    "    pb_np = np.array(imo)\n",
    "\n",
    "    aaa = img_name.split(\".\")\n",
    "    bbb = aaa[0:-1]\n",
    "    imidx = bbb[0]\n",
    "    for i in range(1,len(bbb)):\n",
    "        imidx = imidx + \".\" + bbb[i]\n",
    "\n",
    "    # imo.save(d_dir+imidx+'.png')\n",
    "    return imo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d:\\\\U-2-Net\\\\input_images\\\\F_03.png']\n",
      "...load U2NET---173.6 MB\n",
      "inferencing: F_03.png\n"
     ]
    }
   ],
   "source": [
    "# --------- 1. get image path and name ---------\n",
    "model_name = 'u2net'#u2netp\n",
    "input_path = 'input_images'\n",
    "output_path = 'result_images'\n",
    "\n",
    "# image_dir = os.path.join(os.getcwd(), 'test_data', 'test_images')\n",
    "# prediction_dir = os.path.join(os.getcwd(), 'test_data', model_name + '_results' + os.sep)\n",
    "image_dir = os.path.join(os.getcwd(), input_path)\n",
    "prediction_dir = os.path.join(os.getcwd(), output_path)\n",
    "model_dir = os.path.join(os.getcwd(), 'saved_models', model_name, model_name + '.pth')\n",
    "\n",
    "img_name_list = glob.glob(image_dir + os.sep + '*')\n",
    "print(img_name_list)\n",
    "\n",
    "# --------- 2. dataloader ---------\n",
    "#1. dataloader\n",
    "test_salobj_dataset = SalObjDataset(img_name_list = img_name_list,\n",
    "                                    lbl_name_list = [],\n",
    "                                    transform=transforms.Compose([RescaleT(320),\n",
    "                                                                    ToTensorLab(flag=0)])\n",
    "                                    )\n",
    "test_salobj_dataloader = DataLoader(test_salobj_dataset,\n",
    "                                    batch_size=1,\n",
    "                                    shuffle=False,\n",
    "                                    num_workers=1)\n",
    "\n",
    "# --------- 3. model define ---------\n",
    "if(model_name=='u2net'):\n",
    "    print(\"...load U2NET---173.6 MB\")\n",
    "    net = U2NET(3,1)\n",
    "elif(model_name=='u2netp'):\n",
    "    print(\"...load U2NEP---4.7 MB\")\n",
    "    net = U2NETP(3,1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net.load_state_dict(torch.load(model_dir))\n",
    "    net.cuda()\n",
    "else:\n",
    "    net.load_state_dict(torch.load(model_dir, map_location='cpu'))\n",
    "net.eval()\n",
    "\n",
    "# --------- 4. inference for each image ---------\n",
    "for i_test, data_test in enumerate(test_salobj_dataloader):\n",
    "\n",
    "    print(\"inferencing:\",img_name_list[i_test].split(os.sep)[-1])\n",
    "\n",
    "    inputs_test = data_test['image']\n",
    "    inputs_test = inputs_test.type(torch.FloatTensor)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        inputs_test = Variable(inputs_test.cuda())\n",
    "    else:\n",
    "        inputs_test = Variable(inputs_test)\n",
    "\n",
    "    d1,d2,d3,d4,d5,d6,d7= net(inputs_test)\n",
    "\n",
    "    # normalization\n",
    "    pred = d1[:,0,:,:]\n",
    "    pred = normPRED(pred)\n",
    "\n",
    "    # save results to test_results folder\n",
    "    if not os.path.exists(prediction_dir):\n",
    "        os.makedirs(prediction_dir, exist_ok=True)\n",
    "    mask = mask_output(img_name_list[i_test],pred,prediction_dir)\n",
    "\n",
    "    # generate remove bg from original image & mask\n",
    "    img = Image.open(os.path.join(input_path, img_name_list[i_test].split(os.sep)[-1]))\n",
    "    w, h = img.size\n",
    "    img_empty = Image.new(\"RGBA\", (w, h), (0, 0, 0, 0))\n",
    "    mask = mask.convert('L').resize(img.size)\n",
    "    out = Image.composite(img, img_empty, mask)\n",
    "    out.save(os.path.join(output_path, img_name_list[i_test].split(os.sep)[-1].split('.')[0] + '.png'))\n",
    "\n",
    "    del d1,d2,d3,d4,d5,d6,d7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove bg by mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = 'test_data/test_images/0002-01.jpg' # original\n",
    "mask_path = 'test_data/u2net_results/0002-01.png' # mask\n",
    "save_path = 'result_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(im_path)\n",
    "w, h = img.size\n",
    "img_empty = Image.new(\"RGBA\", (w, h), (0, 0, 0, 0))\n",
    "mask = Image.open(mask_path).convert('L').resize(img.size)\n",
    "out = Image.composite(img, img_empty, mask)\n",
    "out.save(save_path + 'out.png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afbeeb158273d1461a50b574db872c3900997b16015a5180a5085b7f01b25454"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch1.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
